{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "collapsed": true,
        "id": "hBUUW7lfbdD0",
        "outputId": "51dba898-7080-4cd7-d5ce-545544d1bc84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Collecting google-cloud-texttospeech\n",
            "  Downloading google_cloud_texttospeech-2.25.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (4.25.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.69.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (0.6.1)\n",
            "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading google_cloud_texttospeech-2.25.0-py2.py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.7/186.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, anthropic, google-cloud-texttospeech\n",
            "Successfully installed anthropic-0.49.0 google-cloud-texttospeech-2.25.0 pydub-0.25.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "a1a3e50c46bc4264839a7f4b29812e87",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install anthropic pillow pydub moviepy google-cloud-texttospeech\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlYU1tXQxqU_",
        "outputId": "b0198cf8-7bd9-4ffa-bc14-aa70d54bf75b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 chapter folders\n",
            "--------------------------------------------------\n",
            "No WebP files\n",
            "\n",
            "No low variation images found\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def process_chapters(base_folder):\n",
        "\n",
        "    chapter_folders = sorted([d for d in os.listdir(base_folder)\n",
        "                            if os.path.isdir(os.path.join(base_folder, d))\n",
        "                            and d.lower().startswith('chapter')],\n",
        "                           key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
        "\n",
        "    if not chapter_folders:\n",
        "        print(\"No chapter folder\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(chapter_folders)} chapter folders\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for chapter in chapter_folders:\n",
        "        chapter_path = os.path.join(base_folder, chapter)\n",
        "\n",
        "\n",
        "        convert_webp_to_jpg(chapter_path)\n",
        "\n",
        "\n",
        "        check_low_variation_images(chapter_path)\n",
        "\n",
        "def convert_webp_to_jpg(folder_path, delete_original=True):\n",
        "\n",
        "    webp_files = list(Path(folder_path).glob(\"*.webp\"))\n",
        "    webp_files.extend(Path(folder_path).glob(\"*.WEBP\"))\n",
        "\n",
        "    if not webp_files:\n",
        "        print(\"No WebP files\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(webp_files)} WebP files\")\n",
        "\n",
        "    converted_count = 0\n",
        "    failed_files = []\n",
        "\n",
        "    for webp_path in webp_files:\n",
        "        try:\n",
        "            with Image.open(webp_path) as img:\n",
        "                jpg_path = webp_path.with_suffix('.jpg')\n",
        "\n",
        "                if img.mode in ('RGBA', 'LA'):\n",
        "                    background = Image.new('RGB', img.size, (255, 255, 255))\n",
        "                    background.paste(img, mask=img.split()[-1])\n",
        "                    img = background\n",
        "\n",
        "                img.save(jpg_path, 'JPEG', quality=95)\n",
        "                converted_count += 1\n",
        "\n",
        "                if delete_original:\n",
        "                    webp_path.unlink()\n",
        "\n",
        "            print(f\"Converted: {webp_path.name} -> {jpg_path.name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to convert {webp_path.name}: {str(e)}\")\n",
        "            failed_files.append((webp_path.name, str(e)))\n",
        "\n",
        "    print(f\"Converted {converted_count} WebP files\")\n",
        "    if failed_files:\n",
        "        print(f\"Failed to convert {len(failed_files)} files\")\n",
        "\n",
        "def check_low_variation_images(folder_path, std_threshold=5, move_blanks=True):\n",
        "\n",
        "    def has_low_variation(image_path, threshold):\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                return True, \"Failed to load\", 0\n",
        "\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            std_dev = np.std(gray)\n",
        "\n",
        "            if std_dev < threshold:\n",
        "                return True, f\"Low variation\", std_dev\n",
        "\n",
        "            return False, \"Image valid\", std_dev\n",
        "\n",
        "        except Exception as e:\n",
        "            return True, f\"Error processing image: {str(e)}\", 0\n",
        "\n",
        "    if move_blanks:\n",
        "        low_var_folder = os.path.join(folder_path, 'bad_images')\n",
        "        os.makedirs(low_var_folder, exist_ok=True)\n",
        "\n",
        "    image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')\n",
        "    image_files = [f for f in os.listdir(folder_path)\n",
        "                  if f.lower().endswith(image_extensions)]\n",
        "\n",
        "    low_var_images = []\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "\n",
        "        if 'bad_images' in image_path:\n",
        "            continue\n",
        "\n",
        "        is_low_var, reason, std_dev = has_low_variation(image_path, std_threshold)\n",
        "\n",
        "        if is_low_var:\n",
        "            low_var_images.append((image_file, std_dev))\n",
        "\n",
        "            if move_blanks:\n",
        "                try:\n",
        "                    shutil.move(image_path, os.path.join(low_var_folder, image_file))\n",
        "                    print(f\"Moved: {image_file}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed moving {image_file}: {str(e)}\")\n",
        "\n",
        "    if low_var_images:\n",
        "        print(f\"\\nFound {len(low_var_images)} bad images\")\n",
        "    else:\n",
        "        print(\"\\nNo low variation images found\")\n",
        "\n",
        "\n",
        "base_folder = \"/content/chapters\"\n",
        "process_chapters(base_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OgqaqpdPXzst",
        "outputId": "16703f8c-285b-4e12-eb05-cf35fc1aafb0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import base64\n",
        "import json\n",
        "from PIL import Image\n",
        "import io\n",
        "import anthropic\n",
        "import time\n",
        "\n",
        "\n",
        "scripts_folder = '/content/scripts'\n",
        "os.makedirs(scripts_folder, exist_ok=True)\n",
        "\n",
        "import os\n",
        "import base64\n",
        "import json\n",
        "from PIL import Image\n",
        "import io\n",
        "import anthropic\n",
        "\n",
        "def encode_image(image_path, scale=0.27, min_dimension=100):\n",
        "    \"\"\"Convert image to base64, after resizing to scale x the original size.\"\"\"\n",
        "\n",
        "    extension = os.path.splitext(image_path)[1].lower()\n",
        "\n",
        "\n",
        "    extension_to_format = {\n",
        "        '.jpg': 'JPEG',\n",
        "        '.jpeg': 'JPEG',\n",
        "        '.png': 'PNG'\n",
        "    }\n",
        "\n",
        "\n",
        "    save_format = extension_to_format.get(extension, 'PNG')\n",
        "\n",
        "    with Image.open(image_path) as img:\n",
        "\n",
        "        width, height = img.size\n",
        "        new_width = max(int(width * scale), min_dimension)\n",
        "        new_height = max(int(height * scale), min_dimension)\n",
        "\n",
        "\n",
        "        if new_width == min_dimension:\n",
        "            new_height = int(height * (min_dimension / width))\n",
        "        elif new_height == min_dimension:\n",
        "            new_width = int(width * (min_dimension / height))\n",
        "\n",
        "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
        "\n",
        "\n",
        "        buffered = io.BytesIO()\n",
        "\n",
        "        img.save(buffered, format=save_format)\n",
        "\n",
        "\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "\n",
        "        return {\n",
        "            \"type\": \"image\",\n",
        "            \"source\": {\n",
        "                \"type\": \"base64\",\n",
        "                \"media_type\": f\"image/{save_format.lower()}\",\n",
        "                \"data\": img_str\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "def validate_response(response_text, expected_count=5):\n",
        "    \"\"\"Validate that the response has exactly the expected number of asterisk-terminated lines\"\"\"\n",
        "    lines = [line.strip() for line in response_text.split('*') if line.strip()]\n",
        "    if len(lines) != expected_count:\n",
        "        raise ValueError(f\"Expected {expected_count} lines, but got {len(lines)} lines in response\")\n",
        "    return response_text\n",
        "\n",
        "def process_chapters(chapters_dir, client, manhwa_name):\n",
        "    \"\"\"Process all chapters while maintaining rolling context\"\"\"\n",
        "\n",
        "    initial_messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": manhwa_name}]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"Chain of Thought Summary:\\n\\\"Heavenly Demon Can't Live a Normal Life\\\" follows the story of the mighty Heavenly Demon, a martial arts master who ruled the Murim world with unparalleled strength. After his death by betrayal, he reincarnates into the body of Michael, a weak noble in a medieval fantasy world. Despite trying to live peacefully, his martial arts background and powerful nature constantly draw him into conflicts.\\n\\nThe story combines elements of martial arts, medieval fantasy, and political intrigue. In his new life, Michael must navigate noble society while dealing with threats both internal and external to his territory. His overwhelming power from his previous life as the Heavenly Demon often conflicts with his desire to maintain a low profile, leading to situations where he must balance between showing his true strength and maintaining his cover.\\n\\nThe manhwa explores themes of adaptation, power dynamics, and the struggle between past identity and present circumstances. Michael's journey is complicated by the fact that he must protect his territory and loved ones while dealing with nobles, demons, and various other threats in this new world, all while trying (and often failing) to maintain a \\\"normal\\\" life.\\n\\nThis series is known for its strong character development, intense action sequences, and the interesting contrast between Eastern martial arts and Western fantasy elements. The protagonist's struggle to adapt to a new society while carrying the burden of his past life's power creates unique and often humorous situations.\\n\\nLet me know when you want the intro or to proceed with the panel descriptions.\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": \"intro\"}]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"In a world where power knows no bounds, imagine being the strongest martial artist alive, only to be reborn into a completely different realm. Now, picture trying to live a quiet life when your very nature screams destruction. Follow the journey of a reincarnated Heavenly Demon, who just wants to live normally in his new life as a noble, but fate has other plans. When your every instinct is honed for battle, can you really pretend to be ordinary? Let's dive into this tale of power, restraint, and the hilarious attempts at normalcy by someone who's anything but normal.\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "    messages = initial_messages.copy()\n",
        "\n",
        "\n",
        "    for chapter_name in sorted(os.listdir(chapters_dir)):\n",
        "        if chapter_name == '.ipynb_checkpoints':\n",
        "            continue\n",
        "\n",
        "        chapter_path = os.path.join(chapters_dir, chapter_name)\n",
        "        if os.path.isdir(chapter_path):\n",
        "            print(f\"\\nProcessing {chapter_name}...\")\n",
        "\n",
        "\n",
        "            image_files = [f for f in os.listdir(chapter_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            image_files.sort(key=lambda x: int(x.split('-')[0]))\n",
        "\n",
        "            chapter_responses = []\n",
        "\n",
        "\n",
        "            for i in range(0, len(image_files), 5):\n",
        "                batch = image_files[i:i+5]\n",
        "                batch_data = []\n",
        "\n",
        "                for img_file in batch:\n",
        "                    img_path = os.path.join(chapter_path, img_file)\n",
        "                    img_data = encode_image(img_path)\n",
        "                    batch_data.append(img_data)\n",
        "\n",
        "\n",
        "                messages.append({\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": batch_data\n",
        "                })\n",
        "                time.sleep(5)\n",
        "\n",
        "\n",
        "                message = client.messages.create(\n",
        "                    model=\"claude-3-5-sonnet-20241022\",\n",
        "                    max_tokens=666,\n",
        "                    temperature=0,\n",
        "                    system=\"CRITICAL REQUIREMENT:\\nYOU MUST ALWAYS OUTPUT EXACTLY 5 LINES, NO MORE, NO LESS.\\nEach line must end with an asterisk (*).\\nCount your lines before submitting.\\nIf you have less than 5 lines, continue describing the scene or add context.\\nIf you have more than 5 lines, combine descriptions until you have exactly 5.\\nFAILURE TO PROVIDE EXACTLY 5 LINES IS A CRITICAL ERROR.\\n\\nVERIFICATION STEPS (You must follow these before submitting):\\n1. Count the number of asterisks (*) in your response\\n2. Ensure the count is EXACTLY 5\\n3. If not 5, revise your response before submitting\\n4. Double-check the count one final time\\n\\nYou are a professional Manhwa recap scriptwriter. Your task is to create flowing, engaging scripts for a voice actor who will narrate while panels are shown. Follow these strict guidelines:\\n\\nFORMAT REQUIREMENTS:\\n- Exactly ONE description per panel, followed by ONE asterisk (*)\\n- Each batch MUST have exactly 5 descriptions with 5 asterisks\\n- Maximum 30 words per panel description\\n- End each description with a single asterisk (*)\\n- Combine multiple text boxes or elements within a single panel into one flowing description\\n- When multiple characters speak in the same panel, combine their dialogue into one description\\n- Only write what the narrator is reading out. Do not add instructions on how to read the texts. e.g. do not add \\\"pause for dramatic effect.\\\" or things like \\\"*voice trails off with slight disbelief*\\\" do not give actions as you are not writing a script for a play but a script for narration.\\n- Use character names/aliases consistently after introduction.\\n\\nNARRATIVE STYLE:\\n- Write in a cinematic, flowing style that connects panels\\n- Use active voice and present tense\\n- When characters speak, use \\\"says/said\\\" attribution\\n- For thought bubbles, indicate it's a character's thoughts\\n- Use character names/aliases consistently after introduction\\n- For narration boxes (no character attribution), quote verbatim\\n- Avoid onomatopoeia, sound effects, or reading instructions\\n\\nCONTENT GUIDELINES:\\n1. For first prompt (Manhwa name):\\n   - Create detailed background summary\\n   - Use as context for future descriptions\\n- Multiple speakers in one panel must be combined into a single flowing description\\n- Use commas, conjunctions, or other literary devices to connect multiple speakers naturally\\n- Never split dialogue from the same panel even if spoken by different characters\\n\\n2. For second prompt (\\\"intro\\\"):\\n   - Write brief, spoiler-free hook\\n   - Example: \\\"What happens when the mightiest martial artist...\\\"\\n\\n3. For image prompts:\\n   - Process exactly 5 panels per batch\\n   - Maintain story continuity between panels\\n   - Include essential context and desctriptions for non-visual audience\\n   - Be concise but descriptive\\n   - End descriptions abruptly when little is happening\\n   - Handle scene changes with quick transitions\\n\\nTECHNICAL NOTES:\\n- You'll receive images in base64 JSON format with dimensions\\n- Process images sequentially\\n- Never describe same panel twice\\n- Copyright concerns are pre-cleared\\n\\nQUALITY CHECKS:\\n- MANDATORY: Count asterisks (*) before submitting - MUST BE EXACTLY 5\\n- If less than 5 lines:\\n  * Add additional context to existing descriptions\\n  * Expand on character reactions\\n  * Include environmental details\\n  * Describe background elements\\n  * Add relevant atmospheric details\\n- If more than 5 lines:\\n  * Combine related descriptions\\n  * Merge multiple speakers in same panel\\n  * Consolidate scene descriptions\\n  * Remove redundant information\\n- Never submit unless exactly 5 lines are present\\n- Each line must provide unique information\\n- No empty or placeholder lines allowed\\n\\nRemember: Your goal is to create an engaging, flowing narrative that works both with and without visuals while strictly maintaining the format requirements.\",\n",
        "                    messages=messages\n",
        "                )\n",
        "\n",
        "\n",
        "                response_text = message.content[0].text if isinstance(message.content, list) else message.content\n",
        "\n",
        "\n",
        "                messages.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": [{\"type\": \"text\", \"text\": response_text}]\n",
        "                })\n",
        "\n",
        "\n",
        "                if len(messages) > len(initial_messages) + 20:  \n",
        "\n",
        "                    messages = initial_messages + messages[-(20):]\n",
        "\n",
        "                print(f\"Adding response for batch starting with {batch[0]}\")\n",
        "                chapter_responses.append(response_text)\n",
        "                print(f\"Processed batch {i//5 + 1} ({len(batch)} images)\")\n",
        "                print(f\"Context size: {len(messages)} messages\")\n",
        "\n",
        "\n",
        "            total_images = len(image_files)\n",
        "            last_batch_size = total_images % 5 \n",
        "\n",
        "            if last_batch_size != 0: \n",
        "                print(f\"\\nLast batch had {last_batch_size} images but generated 5 lines\")\n",
        "\n",
        "                last_response = chapter_responses[-1]\n",
        "\n",
        "                lines = [line.strip() for line in last_response.split('*') if line.strip()]\n",
        "\n",
        "                kept_lines = lines[:last_batch_size]\n",
        "\n",
        "                new_last_response = ' *\\n'.join(kept_lines) + ' *'\n",
        "\n",
        "                chapter_responses[-1] = new_last_response\n",
        "                print(f\"Adjusted last batch to {last_batch_size} lines\")\n",
        "\n",
        "            # Save chapter responses\n",
        "            if chapter_responses:\n",
        "                chapter_script_path = os.path.join(scripts_folder, f\"{chapter_name}.txt\")\n",
        "                with open(chapter_script_path, \"w\", encoding='utf-8') as chapter_file:\n",
        "                    chapter_file.write(\"\\n\\n\".join(chapter_responses))\n",
        "                print(f\"Saved script for {chapter_name} at {chapter_script_path}\")\n",
        "\n",
        "def main():\n",
        "    # Initialize Anthropic client\n",
        "    client = anthropic.Anthropic(api_key=\"Key\")\n",
        "\n",
        "\n",
        "    chapters_dir = '/content/chapters'\n",
        "\n",
        "\n",
        "    manhwa_name = \"Heavenly Demon Can't Live a Normal Life\"\n",
        "\n",
        "\n",
        "    process_chapters(chapters_dir, client, manhwa_name)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvlpjDJbm5Uq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxKxHW4x86PO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkETDkgemQbb",
        "outputId": "5c39a0e6-654d-4087-e7d1-5d199010af0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing chapter: .ipynb_checkpoints\n",
            "Saved script for .ipynb_checkpoints at /content/chapters/scripts/.ipynb_checkpoints.txt\n",
            "Processing chapter: chapter1\n",
            "Processing 1-3dTRHPwLYwE3o.jpg...\n",
            "Processing 2-tMfKQgt-BPVx_.jpg...\n",
            "Processing 3-jf-D5GyepxyxU.jpg...\n",
            "Processing 4-cpz3y5iRHhpFE.jpg...\n",
            "Error processing image 4-cpz3y5iRHhpFE.jpg in chapter1: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 40,000 input tokens per minute. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
            "Processing 5-Fr6cT5NnhnpmT.jpg...\n",
            "Error processing image 5-Fr6cT5NnhnpmT.jpg in chapter1: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 40,000 input tokens per minute. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
            "Processing 6-lA8haq2Jj6Cm7.jpg...\n",
            "Error processing image 6-lA8haq2Jj6Cm7.jpg in chapter1: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 40,000 input tokens per minute. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
            "Processing 7-a0f1SWXdC4H4O.jpg...\n",
            "Error processing image 7-a0f1SWXdC4H4O.jpg in chapter1: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 40,000 input tokens per minute. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
            "Processing 8-WghY7R6phYP5G.jpg...\n",
            "Error processing image 8-WghY7R6phYP5G.jpg in chapter1: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 40,000 input tokens per minute. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
            "Processing 9-VHyDtgqjn-1Ye.jpg...\n",
            "Error processing image 9-VHyDtgqjn-1Ye.jpg in chapter1: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 40,000 input tokens per minute. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
            "Processing 10-QxMFXNXPW4a5P.jpg...\n",
            "Error processing image 10-QxMFXNXPW4a5P.jpg in chapter1: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 40,000 input tokens per minute. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
            "Saved script for chapter1 at /content/chapters/scripts/chapter1.txt\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvCAAoGmYHrB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Farc13BN2_gS",
        "outputId": "477fcbc9-b997-4c5f-a017-7585054a730d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated file: /content/scripts/chapter2.txt\n",
            "Updated file: /content/scripts/chapter1.txt\n",
            "Replacement complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "folder_path = \"/content/scripts\"\n",
        "\n",
        "def replace_asterisks_with_marks(file_path):\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        contents = f.read()\n",
        "\n",
        "    marker_counter = 1\n",
        "\n",
        "    def mark_replacer(match):\n",
        "        nonlocal marker_counter\n",
        "        replacement = f'<mark name=\"p{marker_counter}\"/>'\n",
        "        marker_counter += 1\n",
        "        return replacement\n",
        "\n",
        "\n",
        "    updated_contents = re.sub(r'\\*', mark_replacer, contents)\n",
        "\n",
        "\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(updated_contents)\n",
        "\n",
        "    print(f\"Updated file: {file_path}\")\n",
        "\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        replace_asterisks_with_marks(file_path)\n",
        "\n",
        "print(\"Replacement complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbGqi9OUrH8N",
        "outputId": "4bab2ee1-6765-438b-eab7-704ccf420780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160\n"
          ]
        }
      ],
      "source": [
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    contents = file.read()\n",
        "print(contents.count(\"<break time=\\\"2600ms\\\"/>\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4Gp2Hk_RYST"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYs5MGbfauFT",
        "outputId": "2abf1f35-f408-46ae-fe08-0a9548c6687d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing Summary:\n",
            "Chapter 1:\n",
            "  Audio: output/audio/chapter1.mp3\n",
            "  Marks: 5\n",
            "Chapter 2:\n",
            "  Audio: output/audio/chapter2.mp3\n",
            "  Marks: 5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "import base64\n",
        "from pydub import AudioSegment\n",
        "from typing import List, Tuple, Dict\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "class TTSPipeline:\n",
        "    def __init__(self, api_key: str, scripts_folder: str, base_output_folder: str):\n",
        "        self.api_key = api_key\n",
        "        self.scripts_folder = scripts_folder\n",
        "        self.base_output_folder = base_output_folder\n",
        "        self.audio_folder = os.path.join(base_output_folder, \"audio\")\n",
        "        self.timepoint_folder = os.path.join(base_output_folder, \"timepoints\")\n",
        "        self.voice_name = \"en-US-Wavenet-D\"\n",
        "        self.max_ssml_length = 4900\n",
        "        self.tts_url = f\"https://texttospeech.googleapis.com/v1beta1/text:synthesize?key={api_key}\"\n",
        "\n",
        "        os.makedirs(self.audio_folder, exist_ok=True)\n",
        "        os.makedirs(self.timepoint_folder, exist_ok=True)\n",
        "\n",
        "    def split_ssml_into_chunks(self, ssml_text: str) -> List[str]:\n",
        "        \"\"\"Splits SSML text into smaller chunks while preserving <mark> tags.\"\"\"\n",
        "\n",
        "        text = ssml_text.strip()\n",
        "        if text.startswith(\"<speak>\"):\n",
        "            text = text[7:]\n",
        "        if text.endswith(\"</speak>\"):\n",
        "            text = text[:-8]\n",
        "\n",
        "\n",
        "        if len(text) <= self.max_ssml_length:\n",
        "            return [f\"<speak>{text.strip()}</speak>\"]\n",
        "\n",
        "\n",
        "        parts = re.split(r'(<mark name=\"[^\"]+\"/>)', text)\n",
        "\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "        for part in parts:\n",
        "\n",
        "            if len(current_chunk) + len(part) > self.max_ssml_length:\n",
        "                if current_chunk:\n",
        "                    chunks.append(f\"<speak>{current_chunk.strip()}</speak>\")\n",
        "                    current_chunk = \"\"\n",
        "            current_chunk += part\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(f\"<speak>{current_chunk.strip()}</speak>\")\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def synthesize_ssml(self, ssml_chunk: str, output_file: str) -> Dict:\n",
        "\n",
        "        payload = {\n",
        "            \"input\": {\"ssml\": ssml_chunk},\n",
        "            \"voice\": {\n",
        "                \"languageCode\": \"en-US\",\n",
        "                \"name\": self.voice_name,\n",
        "                \"ssmlGender\": \"MALE\"\n",
        "            },\n",
        "            \"audioConfig\": {\n",
        "                \"audioEncoding\": \"MP3\",\n",
        "                \"speakingRate\": 1.1\n",
        "            },\n",
        "            \"enableTimePointing\": [\"SSML_MARK\"]\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(self.tts_url, json=payload)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if 'audioContent' not in data:\n",
        "                raise ValueError(\"No audio content in API response\")\n",
        "\n",
        "\n",
        "            audio_content = base64.b64decode(data['audioContent'])\n",
        "            with open(output_file, \"wb\") as out:\n",
        "                out.write(audio_content)\n",
        "\n",
        "\n",
        "            audio = AudioSegment.from_file(output_file)\n",
        "            duration = len(audio) / 1000.0\n",
        "\n",
        "\n",
        "            timepoints = data.get(\"timepoints\", [])\n",
        "\n",
        "            return {\n",
        "                \"duration\": duration,\n",
        "                \"timepoints\": timepoints\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"TTS API error: {str(e)}\")\n",
        "            if 'response' in locals():\n",
        "                logging.error(f\"Response content: {response.text}\")\n",
        "            raise\n",
        "\n",
        "    def process_chapter(self, txt_file_path: str, chapter_number: int) -> Tuple[str, List[Dict]]:\n",
        "        \"\"\"Processes an entire chapter: generates TTS, timestamps, and combines chunks.\"\"\"\n",
        "        audio_file = os.path.join(self.audio_folder, f\"chapter{chapter_number}.mp3\")\n",
        "        timepoint_file = os.path.join(self.timepoint_folder, f\"chapter{chapter_number}.json\")\n",
        "\n",
        "        temp_dir = os.path.join(self.base_output_folder, \"temp\")\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "        with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            raw_text = f.read().strip()\n",
        "\n",
        "        ssml_text = f\"<speak>{raw_text}</speak>\"\n",
        "        chunks = self.split_ssml_into_chunks(ssml_text)\n",
        "        logging.info(f\"Processing chapter {chapter_number}: {len(chunks)} chunks\")\n",
        "\n",
        "        chunk_files = []\n",
        "        global_timepoints = []\n",
        "        current_offset = 0.0\n",
        "\n",
        "        for i, chunk in enumerate(chunks, start=1):\n",
        "            chunk_file = os.path.join(temp_dir, f\"chapter{chapter_number}_chunk{i}.mp3\")\n",
        "            result = self.synthesize_ssml(chunk, chunk_file)\n",
        "            chunk_files.append(chunk_file)\n",
        "\n",
        "\n",
        "            for tp in result[\"timepoints\"]:\n",
        "                global_timepoints.append({\n",
        "                    \"markName\": tp[\"markName\"],\n",
        "                    \"timeSeconds\": current_offset + tp[\"timeSeconds\"]\n",
        "                })\n",
        "\n",
        "            current_offset += result[\"duration\"]\n",
        "\n",
        "\n",
        "        combined_audio = AudioSegment.empty()\n",
        "        for chunk_file in chunk_files:\n",
        "            chunk_audio = AudioSegment.from_file(chunk_file)\n",
        "            combined_audio += chunk_audio\n",
        "\n",
        "        combined_audio.export(audio_file, format=\"mp3\")\n",
        "\n",
        "\n",
        "        for chunk_file in chunk_files:\n",
        "            os.remove(chunk_file)\n",
        "        os.rmdir(temp_dir)\n",
        "\n",
        "\n",
        "        with open(timepoint_file, \"w\", encoding=\"utf-8\") as fp:\n",
        "            json.dump(global_timepoints, fp, indent=2)\n",
        "\n",
        "        return audio_file, global_timepoints\n",
        "\n",
        "    def process_all_chapters(self):\n",
        "        \"\"\"Processes all text files in the folder.\"\"\"\n",
        "        results = []\n",
        "        txt_files = [f for f in os.listdir(self.scripts_folder) if f.lower().endswith(\".txt\")]\n",
        "\n",
        "        for filename in sorted(txt_files):\n",
        "            chapter_number = int(re.search(r'\\d+', filename).group())\n",
        "            txt_path = os.path.join(self.scripts_folder, filename)\n",
        "\n",
        "            try:\n",
        "                mp3_path, timepoints = self.process_chapter(txt_path, chapter_number)\n",
        "                results.append({\n",
        "                    \"chapter\": chapter_number,\n",
        "                    \"audio\": mp3_path,\n",
        "                    \"timepoints\": len(timepoints)\n",
        "                })\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Failed to process chapter {chapter_number}: {str(e)}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    API_KEY = \"KEY\"\n",
        "    SCRIPTS_FOLDER = \"/content/scripts\"\n",
        "    OUTPUT_FOLDER = \"output\"\n",
        "\n",
        "    pipeline = TTSPipeline(API_KEY, SCRIPTS_FOLDER, OUTPUT_FOLDER)\n",
        "    results = pipeline.process_all_chapters()\n",
        "\n",
        "    print(\"\\nProcessing Summary:\")\n",
        "    for result in results:\n",
        "        print(f\"Chapter {result['chapter']}:\")\n",
        "        print(f\"  Audio: {result['audio']}\")\n",
        "        print(f\"  Marks: {result['timepoints']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQDVeEY_E69M",
        "outputId": "5d93fbcd-49bf-4ad2-8f39-396ccd273526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOgyi5ukMBfm"
      },
      "outputs": [],
      "source": [
        "AIzaSyC4Q0kSYE6TjF6tbfr0pVmPlaR34-6ogKM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNpJjVLOCucF",
        "outputId": "28b78c5b-abcd-4476-e268-adc224cbc8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zipped folders '/content/output/audio' and '/content/output/timepoints' into '/content/zipfile1.zip'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zip_two_folders(zip_filename, folder1, folder2):\n",
        "    \"\"\"\n",
        "    Creates a ZIP file (zip_filename) that contains all files\n",
        "    from folder1 and folder2.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        # Add folder1\n",
        "        for root, _, files in os.walk(folder1):\n",
        "            for file in files:\n",
        "                full_path = os.path.join(root, file)\n",
        "                # Keep the folder structure in the ZIP archive\n",
        "                arcname = os.path.relpath(full_path, os.path.dirname(folder1))\n",
        "                zipf.write(full_path, arcname)\n",
        "\n",
        "        # Add folder2\n",
        "        for root, _, files in os.walk(folder2):\n",
        "            for file in files:\n",
        "                full_path = os.path.join(root, file)\n",
        "                # Keep the folder structure in the ZIP archive\n",
        "                arcname = os.path.relpath(full_path, os.path.dirname(folder2))\n",
        "                zipf.write(full_path, arcname)\n",
        "\n",
        "# Example usage\n",
        "zip_path = \"/content/zipfile1.zip\"\n",
        "audio_folder = \"/content/output/audio\"\n",
        "timepoints_folder = \"/content/output/timepoints\"\n",
        "\n",
        "zip_two_folders(zip_path, audio_folder, timepoints_folder)\n",
        "print(f\"Zipped folders '{audio_folder}' and '{timepoints_folder}' into '{zip_path}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsT2THKcPHcN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXQ9v8QCPxT5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F2LrbP5Pwsz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ4bi6sIPwTX",
        "outputId": "661a2cfc-7220-45f0-82d1-c5e47a67aa87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing chapter: chapter1...\n",
            "Processed batch 1 (5 images)\n",
            "Processed batch 2 (5 images)\n",
            "Processed batch 3 (5 images)\n",
            "Processed batch 4 (5 images)\n",
            "Processed batch 5 (5 images)\n",
            "Processed batch 6 (5 images)\n",
            "Processed batch 7 (5 images)\n",
            "Processed batch 8 (5 images)\n",
            "Processed batch 9 (5 images)\n",
            "Processed batch 10 (5 images)\n",
            "Processed batch 11 (5 images)\n",
            "Processed batch 12 (5 images)\n",
            "Processed batch 13 (5 images)\n",
            "Processed batch 14 (5 images)\n",
            "Processed batch 15 (5 images)\n",
            "Processed batch 16 (5 images)\n",
            "Processed batch 17 (5 images)\n",
            "Processed batch 18 (5 images)\n",
            "Processed batch 19 (5 images)\n",
            "Processed batch 20 (5 images)\n",
            "Processed batch 21 (5 images)\n",
            "Processed batch 22 (5 images)\n",
            "Processed batch 23 (5 images)\n",
            "Processed batch 24 (5 images)\n",
            "Processed batch 25 (5 images)\n",
            "Processed batch 26 (5 images)\n",
            "Processed batch 27 (5 images)\n",
            "Saved script for chapter 'chapter1' at /content/scripts/chapter1.txt\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
